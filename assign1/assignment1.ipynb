{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panorama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86be819",
   "metadata": {},
   "source": [
    "**What you’ll implement.**\n",
    "- Gaussian smoothing and **Derivative-of-Gaussian**.\n",
    "- Scale-space: **Gaussian/DoG pyramid**, 3×3×3 NMS, contrast & **Hessian edge rejection**.\n",
    "- SIFT pipeline: **orientation assignment** and **128-D descriptor** .\n",
    "- **Homography** via normalized **DLT**, and **RANSAC** for robust estimation.\n",
    "- **Inverse warping** + simple **feather blending** to compose the panorama.\n",
    "\n",
    "**What you’ll deliver.**\n",
    "1) Working code that stitches images.  \n",
    "2) Visual checks at each stage (SIFT → matching → RANSAC → stitching).  \n",
    "3) Written answers in Discussion section.\n",
    "\n",
    "<!-- > **Coordinate note (octave coordinates → original image):**  \n",
    "> Keypoints are `(o, s, y, x)` in octave space. Original pixel ≈ `(x*2^o, y*2^o)`. -->\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [0. Setup & Data](#stage-0)\n",
    "- [1. SIFT ](#stage-1)\n",
    "- [2. Matching (L2 + cross-check)](#stage-2)\n",
    "- [3. RANSAC + Homography](#stage-3)\n",
    "- [4. Warping, Blending & Panorama](#stage-4)\n",
    "- [5. Discussion: Parameter playground](#stage-5)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Implementation TODO\n",
    "\n",
    "- **sift/gaussian.py**  [5pt] \n",
    "  - `gaussian_kernel_1d` \n",
    "  - `image_gradients`   \n",
    "\n",
    "- **sift/dog.py**  [2pt] \n",
    "  - `build_gaussian_pyramid`              \n",
    "\n",
    "- **sift/keypoint_filter.py** [3pt]  \n",
    "  - `hessian_edge_reject`   \n",
    "\n",
    "- **sift/orientation.py** [5pt] \n",
    "  - `orientation_assignment`  \n",
    "\n",
    "- **sift/descriptor.py**  [5pt] \n",
    "  - `sift_descriptor`        \n",
    "\n",
    "- assignmnet1.ipynb  [10pt] \n",
    "  - `sift`     \n",
    "\n",
    "- **matcher.py**  [5pt] \n",
    "  - `match_l2_crosscheck`   \n",
    "\n",
    "- **geom/dlt.py** [10pt]\n",
    "  - `dlt_homography`         \n",
    "\n",
    "- **geom/ransac.py** [10pt]\n",
    "  - `ransac_homography`    \n",
    "\n",
    "- **geom/warp.py**  [5pt] \n",
    "  - `warp_inverse_map`     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511afee9",
   "metadata": {},
   "source": [
    "<a id=\"stage-0\"></a>\n",
    "## Stage 0 — Setup & Data\n",
    "\n",
    "Make sure to set a correct data folder!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97b594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: hill\n",
      "Loaded 3 images\n",
      "Cache root: cache/hill\n",
      "SIFT cache: cache/hill/sift\n",
      "Match cache: cache/hill/matches\n",
      "RANSAC cache: cache/hill/ransac\n",
      "Layout cache: cache/hill/layout\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import hashlib, json, os\n",
    "from pathlib import Path\n",
    "import release.utils.viz_utils as V\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "\n",
    "dataset = \"hill\" # NOTE: Use \"hill\" \n",
    " \n",
    "IMAGE_DIR = f\"./data/{dataset}\"\n",
    "name = os.path.basename(IMAGE_DIR)\n",
    "print(\"Dataset:\", name)\n",
    "\n",
    "IMAGES = f'{IMAGE_DIR}/*.jpg'   \n",
    "CACHE_DIR = 'cache' \n",
    "OUT_DIR=f'outputs/{dataset}'\n",
    "\n",
    "REF=None\n",
    "seed=0\n",
    "sigma0=1.6\n",
    "octaves=4\n",
    "scales=3\n",
    "contrast_th=0.03\n",
    "edge_th=10.0\n",
    "max_kp=1000\n",
    "\n",
    "iters=4000\n",
    "ransac_th=3.0 \n",
    "\n",
    "feather_sigma=15.0\n",
    "\n",
    "files = sorted(glob.glob(IMAGES))\n",
    "assert len(files)>=2, \"Need >=2 images\"\n",
    "print(\"Loaded\", len(files), \"images\")\n",
    "\n",
    "\n",
    "CACHE_ROOT = Path(CACHE_DIR)/name\n",
    "SIFT_DIR   = CACHE_ROOT/'sift'\n",
    "MATCH_DIR  = CACHE_ROOT/'matches'\n",
    "RANSAC_DIR = CACHE_ROOT/'ransac'\n",
    "LAYOUT_DIR = CACHE_ROOT/'layout'\n",
    "print(\"Cache root:\", CACHE_ROOT)\n",
    "print(\"SIFT cache:\", SIFT_DIR)\n",
    "print(\"Match cache:\", MATCH_DIR)\n",
    "print(\"RANSAC cache:\", RANSAC_DIR)\n",
    "print(\"Layout cache:\", LAYOUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c67beb",
   "metadata": {},
   "source": [
    "<a id=\"stage-1\"></a>\n",
    "## Stage 1 — SIFT \n",
    "\n",
    "**You implement (see `sift/`):**\n",
    "- `gaussian.py`: `gaussian_kernel_1d`, `image_gradients` (Derivative-of-Gaussian).\n",
    "- `dog.py`: `build_gaussian_pyramid`.\n",
    "- `keypoint_filter.py`: `hessian_edge_reject`.\n",
    "- `orientation.py`: `orientation_assignment`.\n",
    "- `descriptor.py`: `sift_descriptor`.\n",
    "- code below: `compute_sift`.\n",
    "\n",
    "**What the code below will do (unchanged):**\n",
    "- Build Gaussian/DoG pyramids.  \n",
    "- Detect scale-space extrema, apply contrast/edge rejection.  \n",
    "- Assign orientation(s), compute 128-D descriptors.  \n",
    "- Visualize: keypoints overlay + descriptor sampling sanity checks.\n",
    "\n",
    "**Parameter notes (starting points):**\n",
    "- `sigma0=1.6, octaves=4, scales=3`  \n",
    "- `contrast_th≈0.03, edge_th≈10`  \n",
    "- `max_kp` controls how many keypoints are kept after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed51902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from sift.dog import build_gaussian_pyramid, build_dog_pyramid, nms_3d\n",
    "from sift.keypoint_filter import filter_keypoints\n",
    "from sift.orientation import orientation_assignment\n",
    "from sift.descriptor import sift_descriptor\n",
    "\n",
    "import hashlib, numpy as np, os\n",
    "def _sha1_bytes(path):\n",
    "    import hashlib\n",
    "    h=hashlib.sha1()\n",
    "    with open(path,'rb') as f:\n",
    "        for ch in iter(lambda:f.read(1<<20), b''): h.update(ch)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def compute_sift(img_path, cache_dir='cache/sift',\n",
    "                 sigma0=1.6, octaves=4, scales=3,\n",
    "                 contrast_th=0.03, edge_th=10.0, max_kp=1000):\n",
    "    \"\"\"\n",
    "    Slide-only SIFT extractor with on-disk caching.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    img_path    : str/Path to an image (RGB or grayscale)\n",
    "    cache_dir   : str/Path, where .npz cache files are stored\n",
    "    sigma0      : float, base sigma for the first level in each octave\n",
    "    octaves     : int, number of octaves\n",
    "    scales      : int, S (S+3 Gaussian levels per octave)\n",
    "    contrast_th : float, DoG contrast threshold for candidate suppression\n",
    "    edge_th     : float, Hessian edge rejection parameter (r)\n",
    "    max_kp      : int, max number of keypoints/descriptors to keep\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    pts  : (N,2) float32, keypoint locations in the **original image** coords\n",
    "    desc : (N,128) float32 SIFT descriptors (may be empty if no kp survived)\n",
    "\n",
    "    Slides basis\n",
    "    ------------\n",
    "    - Gaussian/DoG pyramid → 3×3×3 NMS (scale-space extrema) → contrast + Hessian edge\n",
    "    - Orientation assignment → 128-D descriptor (4×4 cells × 8 bins)\n",
    "    \"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    key = _sha1_bytes(img_path)[:16] + f'_{sigma0}_{octaves}_{scales}_{contrast_th}_{edge_th}_{max_kp}'\n",
    "    out = Path(cache_dir) / f\"{Path(img_path).stem}_{key}.npz\"\n",
    "    if out.exists():\n",
    "        z = np.load(out)\n",
    "        return z['pts'].astype(np.float32), z['desc'].astype(np.float32)\n",
    "    g=np.array(Image.open(img_path).convert('L'), dtype=np.float64)/255.0\n",
    "    \n",
    "    #############################\n",
    "    ######### Implement here ####\n",
    "    # Build Gaussian/DoG pyramids.\n",
    "    # Find scale-space extrema with 3×3×3 NMS (+ contrast), then apply Hessian edge rejection.\n",
    "    # For each surviving keypoint (limit to max_kp):\n",
    "    #   - assign one or more dominant orientations (slides’ peak rule)\n",
    "    #   - compute 128-D descriptor per orientation (skip if out-of-bounds)\n",
    "    #   - convert octave coords (o,s,y,x) to original image coords using 2^o\n",
    "    #   - append point and descriptor to Python lists (pts, desc)\n",
    "    # Finally convert pts -> np.array(float32), desc -> stacked float32 (or empty (0,128)).\n",
    "    #############################\n",
    "    raise NotImplementedError\n",
    "\n",
    "    # The rest (caching & return) is provided:\n",
    "    pts = np.array(pts, np.float32)\n",
    "    desc = np.stack(desc, 0).astype(np.float32) if len(desc) else np.empty((0, 128), np.float32)\n",
    "    np.savez_compressed(out, pts=pts, desc=desc)\n",
    "    return pts, desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e74da",
   "metadata": {},
   "source": [
    "### SIFT & Key points Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f29690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pts_list, desc_list = [], []\n",
    "for p in files:\n",
    "    pts, desc = compute_sift(p, cache_dir=SIFT_DIR ,\n",
    "                                     sigma0=sigma0, octaves=octaves, scales=scales,\n",
    "                                     contrast_th=contrast_th, edge_th=edge_th, max_kp=max_kp)\n",
    "    pts_list.append(pts); desc_list.append(desc)\n",
    "\n",
    "# 첫 3장 키포인트 오버레이 보기\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(min(3, len(files))):\n",
    "    kp_img = V.draw_keypoints(files[i], pts_list[i], max_points=1500, r=2)\n",
    "    plt.figure(figsize=(6,4)); plt.imshow(kp_img); plt.title(f'Keypoints: img {i}'); plt.axis('off'); plt.show()\n",
    "    print(f'img {i}: {len(pts_list[i])} keypoints')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12469f4",
   "metadata": {},
   "source": [
    "<a id=\"stage-2\"></a>\n",
    "## Stage 2 — Matching (L2 + cross-check)\n",
    "\n",
    "**You implement:**\n",
    "- `matcher.py`: `match_l2_crosscheck` (mutual nearest neighbors in L2).\n",
    "\n",
    "**What the code below will do (unchanged):**\n",
    "- Match descriptors for each adjacent image pair.  \n",
    "- Visualize a subset of matches **before RANSAC** (random draw).\n",
    "\n",
    "**Tips:**\n",
    "- (Optional) Lowe ratio can be used in experiments, but the required baseline is L2 + cross-check.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3144abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from match.matcher import *\n",
    "\n",
    "\n",
    "def match(i, j, cache_dir, desc_i, desc_j,\n",
    "          method: str = \"crosscheck\",      # \"crosscheck\" or \"ratio\" (bonus)\n",
    "          ratio: float = 0.75,              # only used when method == \"ratio\"\n",
    "          cross_check: bool = True,         # used in bonus mode\n",
    "):\n",
    "    \"\"\"\n",
    "    Return index arrays (idx_i, idx_j) for matches between descriptors of image i and j.\n",
    "\n",
    "    Slide-first policy:\n",
    "    - default method=\"crosscheck\" (mutual nearest neighbors in L2) \n",
    "    - method=\"ratio\" enables Lowe ratio test\n",
    "\n",
    "    Cache is invalidated if descriptor counts or method/params differ from the stored file.\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir)\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Cast descriptors to arrays (N,D)\n",
    "    A = np.asarray(desc_i, dtype=np.float32)\n",
    "    B = np.asarray(desc_j, dtype=np.float32)\n",
    "\n",
    "    # cache key includes method & key params so stale caches are avoided\n",
    "    tag = f\"{method}_nA{len(A)}_nB{len(B)}\"\n",
    "    if method == \"ratio\":\n",
    "        tag += f\"_r{ratio:.2f}_xchk{int(bool(cross_check))}\"\n",
    "    fn = cache_dir / f\"pair_{i}_{j}_{tag}.npz\"\n",
    "\n",
    "    # try cache\n",
    "    if fn.exists():\n",
    "        z = np.load(fn)\n",
    "        idx_i = z[\"idx_i\"].astype(np.int32)\n",
    "        idx_j = z[\"idx_j\"].astype(np.int32)\n",
    "        ok = (len(idx_i) == len(idx_j) and\n",
    "              (len(idx_i) == 0 or (idx_i.max() < len(A) and idx_j.max() < len(B))))\n",
    "        if ok:\n",
    "            return idx_i, idx_j  # use cache\n",
    "\n",
    "    # --- recompute ---\n",
    "    if method == \"crosscheck\":\n",
    "        # slides baseline\n",
    "        pairs = match_l2_crosscheck(A, B)          # expects [(i, j, dist), ...]\n",
    "    elif method == \"ratio\":\n",
    "        # option\n",
    "        pairs = match_lowe_ratio(A, B, ratio=ratio, cross_check=cross_check)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "    # convert to index arrays\n",
    "    if len(pairs) == 0:\n",
    "        idx_i = np.empty((0,), np.int32)\n",
    "        idx_j = np.empty((0,), np.int32)\n",
    "    else:\n",
    "        idx_i = np.fromiter((p[0] for p in pairs), count=len(pairs), dtype=np.int32)\n",
    "        idx_j = np.fromiter((p[1] for p in pairs), count=len(pairs), dtype=np.int32)\n",
    "\n",
    "    np.savez_compressed(fn, idx_i=idx_i, idx_j=idx_j)\n",
    "    return idx_i, idx_j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a3f55",
   "metadata": {},
   "source": [
    "### Matching Visualization (Before RANSAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "i,j = 0,1\n",
    "idx_i, idx_j = match(i, j, MATCH_DIR, desc_list[i], desc_list[j])\n",
    "\n",
    "pairs = list(zip(idx_i.tolist(), idx_j.tolist()))\n",
    "m_img = V.draw_matches(files[i], files[j], pts_list[i], pts_list[j], pairs, inliers=None, max_draw=200)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,5)); plt.imshow(m_img); plt.title('Matches before RANSAC'); plt.axis('off'); plt.show()\n",
    "print('matches:', len(pairs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21984b1",
   "metadata": {},
   "source": [
    "<a id=\"stage-3\"></a>\n",
    "## Stage 3 — RANSAC + Homography (normalized DLT)\n",
    "\n",
    "**You implement:**\n",
    "- `geom/dlt.py`: `dlt_homography`.\n",
    "- `geom/ransac.py`: `ransac_homography`.\n",
    "\n",
    "**What the code below will do (unchanged):**\n",
    "- Estimate `H` and inliers for each adjacent pair.  \n",
    "- Plot matches with **inliers (green)** / **outliers (red)**.  \n",
    "- Draw a small histogram of **symmetric reprojection error**.\n",
    "\n",
    "**Parameter notes:**\n",
    "- `iters` (e.g., 2000–6000), `ransac_th` in pixels (e.g., 3–4), `seed` fixed for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f98350",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from geom.ransac import ransac_homography\n",
    "\n",
    "def ransac(i, j, cache_dir, pts_i, pts_j, idx_i, idx_j, iters, ransac_th, seed):\n",
    "    \"\"\"\n",
    "    Estimate a homography H for pair (i, j) using RANSAC, with simple on-disk caching.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    i, j : int\n",
    "        Indices of the two images in the sequence (only used for cache key).\n",
    "    cache_dir : str or Path\n",
    "        Directory to store/read cached RANSAC results.\n",
    "    pts_i, pts_j : (Ni, 2) and (Nj, 2) float arrays\n",
    "        2D keypoint coordinates (in original image coordinates) for image i and j.\n",
    "    idx_i, idx_j : (M,) int arrays\n",
    "        Matched indices into pts_i and pts_j respectively.\n",
    "    iters : int\n",
    "        Number of RANSAC iterations.\n",
    "    ransac_th : float\n",
    "        Inlier threshold in pixels (symmetric transfer error).\n",
    "    seed : int\n",
    "        RNG seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H : (3, 3) float array or None\n",
    "        Estimated homography mapping points from image i to image j.\n",
    "    inliers : (M,) bool array\n",
    "        Inlier mask for the given matches; empty mask if fewer than 4 valid matches.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * Uses a very simple cache keyed by the pair indices and the number of matches.\n",
    "      If the cached inlier array length mismatches current matches, it recomputes.\n",
    "    * A safety mask removes matches whose indices are out of bounds.\n",
    "    \"\"\"\n",
    "    cache_dir = Path(cache_dir); cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fn = cache_dir / f\"H_{i}_{j}_m{len(idx_i)}.npz\"\n",
    "\n",
    "    # Try cache first\n",
    "    if fn.exists():\n",
    "        z = np.load(fn)\n",
    "        H   = z[\"H\"].astype(np.float64)\n",
    "        inl = z[\"inliers\"].astype(bool)\n",
    "        # Reuse cache only if match count agrees\n",
    "        if len(inl) == len(idx_i):\n",
    "            return H, inl\n",
    "\n",
    "    # --- Recompute (apply a safety mask on indices) ---\n",
    "    mask = (idx_i >= 0) & (idx_i < len(pts_i)) & (idx_j >= 0) & (idx_j < len(pts_j))\n",
    "    idx_i2 = idx_i[mask]; idx_j2 = idx_j[mask]\n",
    "    if len(idx_i2) < 4:\n",
    "        # Fewer than 4 correspondences: homography cannot be estimated\n",
    "        return None, np.zeros(0, dtype=bool)\n",
    "\n",
    "    mA = pts_i[idx_i2].astype(np.float64)\n",
    "    mB = pts_j[idx_j2].astype(np.float64)\n",
    "\n",
    "    H, inl = ransac_homography(mA, mB, iters=iters, thresh=ransac_th, seed=seed)\n",
    "\n",
    "    # Persist result\n",
    "    np.savez_compressed(fn, H=H, inliers=inl.astype(np.uint8))\n",
    "    return H, inl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7dacc",
   "metadata": {},
   "source": [
    "### ▶️ RANSAC inlier & Error histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d45bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "H,inl = ransac(i, j, RANSAC_DIR, pts_list[i], pts_list[j], idx_i, idx_j, iters, ransac_th, seed)\n",
    "m_img_inl = V.draw_matches(files[i], files[j], pts_list[i], pts_list[j], pairs, inliers=inl, max_draw=200)\n",
    "plt.figure(figsize=(12,5)); plt.imshow(m_img_inl); plt.title('Matches with Inliers (green) / Outliers (red)'); plt.axis('off'); plt.show()\n",
    "# symmetric reprojection error\n",
    "X1 = np.hstack([pts_list[i][idx_i], np.ones((len(idx_i),1))])\n",
    "X2 = np.hstack([pts_list[j][idx_j], np.ones((len(idx_j),1))])\n",
    "p = (H @ X1.T).T; p = p[:,:2]/p[:,2,None]\n",
    "e1 = np.linalg.norm(p - pts_list[j][idx_j], axis=1)\n",
    "Hinv = np.linalg.inv(H); p2 = (Hinv @ X2.T).T; p2 = p2[:,:2]/p2[:,2,None]\n",
    "e2 = np.linalg.norm(p2 - pts_list[i][idx_i], axis=1)\n",
    "err = 0.5*(e1+e2)\n",
    "V.plot_hist(err, title='Symmetric reprojection error (px)')\n",
    "print('inliers:', int(inl.sum()), '/', len(inl))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba8ae1",
   "metadata": {},
   "source": [
    "<a id=\"stage-4\"></a>\n",
    "## Stage 4 — Warping, Blending & Panorama\n",
    "\n",
    "**You implement:**\n",
    "- `geom/warp.py`: `warp_inverse_map`.\n",
    "\n",
    "**What the code below will do (unchanged):**\n",
    "- Chain homographies so every image maps to a **common reference** (middle image by default).  \n",
    "- Compute the **output canvas bounds**, apply **inverse warping** per image.  \n",
    "- Blend with **feather blending** (provided in `blend.py`, uses Gaussian smoothing for weights).  \n",
    "- Save the final panorama and intermediate visualizations (weight maps optional).\n",
    "\n",
    "**Parameter note:**\n",
    "- `feather_sigma` controls seam softness (typical: 15–40).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8833c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_left_to_right(pts_list, desc_list, files, cache_match_dir):\n",
    "    \"\"\"\n",
    "    Ensure the image order goes left → right by inspecting a few adjacent pairs.\n",
    "\n",
    "    Strategy\n",
    "    --------\n",
    "    For up to the first 3 adjacent pairs (0-1, 1-2, ...), compute matches and\n",
    "    measure the median horizontal displacement Δx = x_{k+1} - x_k.\n",
    "    If the overall median sign is negative, we reverse the entire sequence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pts_list : list of (Ni, 2) arrays\n",
    "        Keypoint coordinates per image (original image coordinates).\n",
    "    desc_list : list of (Ni, D) arrays\n",
    "        Descriptors per image.\n",
    "    files : list[str or Path]\n",
    "        Image paths, one per item.\n",
    "    cache_match_dir : str or Path\n",
    "        Cache directory used by the `match` function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pts_list_r, desc_list_r, files_r : lists\n",
    "        Possibly reversed lists so that the order is left → right.\n",
    "    \"\"\"\n",
    "    n = len(files)\n",
    "    if n < 2:\n",
    "        return pts_list, desc_list, files\n",
    "\n",
    "    # Inspect a few pairs and aggregate median horizontal shifts\n",
    "    deltas = []\n",
    "    for k in range(min(n - 1, 3)):\n",
    "        idx_i, idx_j = match(k, k + 1, cache_match_dir, desc_list[k], desc_list[k + 1])\n",
    "        if len(idx_i) == 0:\n",
    "            continue\n",
    "        pA = pts_list[k][idx_i]\n",
    "        pB = pts_list[k + 1][idx_j]\n",
    "        deltas.append(np.median(pB[:, 0] - pA[:, 0]))\n",
    "\n",
    "    sign = np.sign(np.median(deltas)) if deltas else +1\n",
    "    if sign < 0:\n",
    "        # Reverse everything if the sequence appears right → left\n",
    "        return list(reversed(pts_list)), list(reversed(desc_list)), list(reversed(files))\n",
    "    return pts_list, desc_list, files\n",
    "\n",
    "\n",
    "# --- Estimate H for all adjacent pairs and chain to a common reference ---\n",
    "pts_list, desc_list, files = ensure_left_to_right(pts_list, desc_list, files, MATCH_DIR)\n",
    "n = len(files)\n",
    "H_pair = []         # homography from k -> k+1\n",
    "pair_idx = []       # index pairs (idx_i, idx_j) used for each H\n",
    "\n",
    "for k in range(n - 1):\n",
    "    idx_i, idx_j = match(k, k + 1, MATCH_DIR, desc_list[k], desc_list[k + 1])\n",
    "    H, inl = ransac(k, k + 1, RANSAC_DIR, pts_list[k], pts_list[k + 1],\n",
    "                    idx_i, idx_j, iters, ransac_th, seed)\n",
    "    print(f'pair {k}->{k+1}: inliers {int(inl.sum())}/{len(inl)}')\n",
    "    H_pair.append(H)\n",
    "    pair_idx.append((idx_i, idx_j))\n",
    "\n",
    "# Choose the reference image (middle by default, or explicit REF)\n",
    "ref = n // 2 if REF is None else int(REF)\n",
    "H_to_ref = [None] * n\n",
    "H_to_ref[ref] = np.eye(3)\n",
    "\n",
    "# Propagate to the right: H(k+1→ref) = inv(H(k→k+1)) @ H(k→ref)\n",
    "for k in range(ref + 1, n):\n",
    "    H_to_ref[k] = np.linalg.inv(H_pair[k - 1]) @ H_to_ref[k - 1]\n",
    "\n",
    "# Propagate to the left:  H(k→ref) = H(k→k+1) @ H(k+1→ref)\n",
    "for k in range(ref - 1, -1, -1):\n",
    "    H_to_ref[k] = H_pair[k] @ H_to_ref[k + 1]\n",
    "\n",
    "# Persist layout for downstream warping/blending and visualize\n",
    "import os; os.makedirs(LAYOUT_DIR, exist_ok=True)\n",
    "np.savez_compressed(LAYOUT_DIR / 'layout.npz', ref=np.int32(ref), H_to_ref=np.stack(H_to_ref))\n",
    "\n",
    "V.visualize_layout(files, H_to_ref)  # shows where each image lands on the canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af212c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from geom.warp import warp_inverse_map\n",
    "from sift.gaussian import gaussian_blur\n",
    "from PIL import Image\n",
    "import release.utils.viz_utils as V\n",
    "\n",
    "def stitch(files, H_to_ref, out_path, sigma=15.0):\n",
    "    \"\"\"\n",
    "    Warp all images into a shared canvas and blend them with feathered weights.\n",
    "\n",
    "    Pipeline\n",
    "    --------\n",
    "    1) Load RGB images to float [0,1].\n",
    "    2) Compute the global canvas bounds by warping each image's 4 corners.\n",
    "    3) For each image:\n",
    "        - compose offset transform T_off with H_to_ref[i] to align to canvas\n",
    "        - inverse warp the color image into the canvas\n",
    "        - build a binary support mask and Gaussian-blur it to get smooth weights\n",
    "    4) Accumulate weighted colors and normalize by the sum of weights.\n",
    "    5) Save the panorama to `out_path`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    files : list[str or Path]\n",
    "        Input image paths in left→right order.\n",
    "    H_to_ref : list[(3,3)]\n",
    "        Homographies that map each image i to the reference frame/canvas.\n",
    "    out_path : str or Path\n",
    "        Output image path (PNG/JPG).\n",
    "    sigma : float\n",
    "        Feathering sigma for the weight maps.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pano : (Hc, Wc, 3) float array in [0,1]\n",
    "        Final blended panorama.\n",
    "    \"\"\"\n",
    "    colors = [np.array(Image.open(p).convert('RGB'), dtype=np.float64) / 255.0 for p in files]\n",
    "\n",
    "    # 1) Canvas bounds from warped corners (min/max over all images)\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(files)):\n",
    "        h, w = colors[i].shape[:2]\n",
    "        corners = np.array([[0, 0, 1], [w, 0, 1], [0, h, 1], [w, h, 1]], dtype=np.float64).T\n",
    "        warp = H_to_ref[i] @ corners\n",
    "        warp = warp[:2] / warp[2:]\n",
    "        xs.extend(warp[0]); ys.extend(warp[1])\n",
    "\n",
    "    xmin, xmax = int(np.floor(min(xs))), int(np.ceil(max(xs)))\n",
    "    ymin, ymax = int(np.floor(min(ys))), int(np.ceil(max(ys)))\n",
    "    Wc, Hc = xmax - xmin, ymax - ymin\n",
    "\n",
    "    # 2) Offset transform to shift everything so that canvas min corner is (0,0)\n",
    "    T_off = np.array([[1, 0, -xmin],\n",
    "                      [0, 1, -ymin],\n",
    "                      [0, 0,    1 ]], dtype=np.float64)\n",
    "\n",
    "    # 3) Accumulate weighted colors\n",
    "    acc  = np.zeros((Hc, Wc, 3), np.float64)\n",
    "    wsum = np.zeros((Hc, Wc),     np.float64)\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        Hc_i = T_off @ H_to_ref[i]\n",
    "        warpI = warp_inverse_map(colors[i], Hc_i, (Hc, Wc), fill=0.0)\n",
    "        mask = (warpI.sum(axis=2) > 1e-6).astype(np.float64)\n",
    "        w = gaussian_blur(mask, sigma=sigma)\n",
    "        acc  += warpI * w[..., None]\n",
    "        wsum += w\n",
    "\n",
    "    pano = acc / (wsum[..., None] + 1e-12)\n",
    "\n",
    "    # 4) Save result\n",
    "    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    Image.fromarray((np.clip(pano, 0, 1) * 255).astype(np.uint8)).save(out_path)\n",
    "    return pano\n",
    "\n",
    "\n",
    "# --- Run the final blending and show the panorama ---\n",
    "out = Path(OUT_DIR) / 'panorama_result.png'\n",
    "pano = stitch(files, H_to_ref, out, sigma=feather_sigma)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.imshow(np.clip(pano, 0, 1))\n",
    "plt.axis('off')\n",
    "plt.title(f'Panorama: {name}')\n",
    "plt.show()\n",
    "print(\"Saved:\", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b3c4ff",
   "metadata": {},
   "source": [
    "<a id=\"stage-5\"></a>\n",
    "## Parameter Playground\n",
    "\n",
    "For each discussion point, you must modify the corresponding parameter in the provided code **at multiple levels** (e.g., smaller, baseline, larger), run the pipeline, and observe how the outcomes change across settings. You should then present at least one piece of supporting evidence (this can be either a visualization or a numerical measurement) that justifies your claim. \n",
    "\n",
    "The goal is not only to record a single result but to **compare different parameter settings** and discuss the trends you observe.\n",
    "\n",
    "- **SIFT detection**\n",
    "  - **`--contrast_th` (Contrast Threshold)** [5pt]\n",
    "    When this parameter is adjusted, discuss how the changes appear in terms of (1) keypoint distribution, (2) matching quality, and (3) panorama stitching.  \n",
    "\n",
    "  - **`--edge_th` (Edge Threshold)** [5pt]  \n",
    "    When this parameter is adjusted, discuss what you observe in (1) the types of keypoints selected, (2) stability of correspondences, and (3) panorama alignment.  \n",
    "\n",
    "  - **`--max_kp` (Maximum Keypoints)** [5pt]  \n",
    "    When this parameter is adjusted, discuss its impact on (1) the number of matches, (2) runtime, and (3) the resulting panorama.  \n",
    "\n",
    "- **Matching**\n",
    "  - **`--match_method {crosscheck, ratio}`** [5pt]  \n",
    "    Compare the results when using cross-check matching versus Lowe ratio matching. Discuss the differences in terms of (1) number of matches, (2) inlier ratio, and (3) panorama quality.  \n",
    "\n",
    "- **RANSAC**\n",
    "  - **`--ransac_th` (Inlier Threshold in pixels)** [5pt]  \n",
    "    When this parameter is adjusted, discuss how it influences (1) inlier selection, (2) model accuracy, and (3) visual quality of the panorama.  \n",
    "\n",
    "  - **`--iters` (Number of Iterations)** [5pt]  \n",
    "    When this parameter is adjusted, discuss the effects on (1) reproducibility of the result, (2) robustness of the homography, and (3) computational cost.\n",
    "\n",
    "- **Homography**\n",
    "  - **DLT Normalization (in `geom/dlt.py`)** [5pt]  \n",
    "    - Compare results with and without normalization. Which one gives lower reprojection error and better panorama stitching?  \n",
    "\n",
    "  - **Failure Case Identification** [5pt]  \n",
    "    You will be given three image sets. Not all of them can be correctly stitched using a single homography.  \n",
    "    - Identify which case fails and explain the reason.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
